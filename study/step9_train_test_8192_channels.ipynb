{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Copyright 2024 National Technology & Engineering Solutions of Sandia, LLC (NTESS). \n",
    "    Under the terms of Contract DE-NA0003525 with NTESS, the U.S. Government retains certain rights in this software.\n",
    "\n",
    "**Step 9 - train/evaluate model on 8192 channel data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from config import (BG_SEED_FILE, DATA_DIR, FG_SEED_FILE, MIX_TEST_FG_SAMPLES,\n",
    "                    MIX_TRAIN_BG_ALPHA, MIX_TRAIN_BG_SAMPLES,\n",
    "                    MIX_TRAIN_BG_SIZE, MIX_TRAIN_FG_LAMBDA,\n",
    "                    MIX_TRAIN_FG_SAMPLES, MODEL_ACTIVITY_L1_REG,\n",
    "                    MODEL_ACTIVITY_L2_REG, MODEL_BATCH_SIZE, MODEL_BETA,\n",
    "                    MODEL_DIR, MODEL_DROPOUT, MODEL_EPOCHS,\n",
    "                    MODEL_HIDDEN_LAYER_ACTIVATION, MODEL_HIDDEN_LAYERS,\n",
    "                    MODEL_INIT_LR, MODEL_KERNEL_L1_REG, MODEL_KERNEL_L2_REG,\n",
    "                    MODEL_LR_SCHED_MIN_DELTA, MODEL_LR_SCHED_PATIENCE,\n",
    "                    MODEL_MIN_DELTA, MODEL_NORMALIZE_SUP_LOSS, MODEL_OOD_FPR,\n",
    "                    MODEL_OPTIMIZER, MODEL_OPTIMIZER_KWARGS, MODEL_PATIENCE,\n",
    "                    MODEL_SPLINE_BINS, MODEL_SPLINE_K, MODEL_SPLINE_S,\n",
    "                    MODEL_SUP_LOSS, MODEL_SUP_NORMALIZE_SCALER,\n",
    "                    MODEL_TARGET_LEVEL, MODEL_TRAIN_ON_GPU,\n",
    "                    MODEL_TRAIN_ON_STATIC_SYNTH_DATA, MODEL_UNSUP_LOSS,\n",
    "                    MODEL_VAL_SPLIT, OOD_SEED_FILE, RANDOM_SEED,\n",
    "                    STATIC_SYNTH_BG_CPS, STATIC_SYNTH_LIVE_TIME_RANGE,\n",
    "                    STATIC_SYNTH_LIVE_TIME_SAMPLING, STATIC_SYNTH_LONG_BG_CPS,\n",
    "                    STATIC_SYNTH_SNR_RANGE, STATIC_SYNTH_SNR_SAMPLING,\n",
    "                    STATIC_SYNTH_SPS, STATIC_SYNTH_TEST_SNR_RANGE, TARGET_ECAL)\n",
    "from riid.data.sampleset import read_hdf\n",
    "from riid.data.synthetic.seed import SeedMixer\n",
    "from riid.data.synthetic.static import StaticSynthesizer\n",
    "from riid.models.neural_nets import LabelProportionEstimator\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from utils import SaveTruthsandPredictionsCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_BINS = 8192\n",
    "file_identifier = \"_8192channels\"\n",
    "BG_MIX_FILE = os.path.join(DATA_DIR, f\"bg_mixtures{file_identifier}.h5\")\n",
    "TRAIN_FILE = os.path.join(DATA_DIR, f\"train.h5\")\n",
    "TRAIN_FG_MIX_FILE = os.path.join(DATA_DIR, f\"train_fg_mixtures{file_identifier}.h5\")\n",
    "TEST_FILE = os.path.join(DATA_DIR, f\"test{file_identifier}.h5\")\n",
    "TEST_FG_MIX_FILE = os.path.join(DATA_DIR, f\"test_fg_mixtures{file_identifier}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Generate IND data for 8192  channels\"\"\"\n",
    "# Set rng\n",
    "rng = np.random.default_rng(seed=RANDOM_SEED)\n",
    "\n",
    "# Load in seeds\n",
    "fg_seeds_ss = read_hdf(FG_SEED_FILE)\n",
    "fg_seeds_ss, _ = fg_seeds_ss.split_fg_and_bg()\n",
    "fg_seeds_ss.drop_sources_columns_with_all_zeros()\n",
    "\n",
    "bg_seeds_ss = read_hdf(BG_SEED_FILE)\n",
    "_, bg_seeds_ss = bg_seeds_ss.split_fg_and_bg()\n",
    "bg_seeds_ss.drop_sources_columns_with_all_zeros()\n",
    "\n",
    "# Get expected source contributions\n",
    "source_counts = {\n",
    "    x.split(\",\")[0]: v\n",
    "    for x, v in zip(\n",
    "        fg_seeds_ss.sources.columns.get_level_values(\"Seed\").values,\n",
    "        fg_seeds_ss.info.total_counts\n",
    "    )\n",
    "}\n",
    "Z = np.array(list(source_counts.values()))\n",
    "expected_props = Z / Z.sum()\n",
    "\n",
    "# Preprocessing\n",
    "fg_seeds_ss = fg_seeds_ss.as_ecal(*TARGET_ECAL)\n",
    "fg_seeds_ss.downsample_spectra(target_bins=TARGET_BINS)\n",
    "fg_seeds_ss.normalize()\n",
    "\n",
    "bg_seeds_ss = bg_seeds_ss.as_ecal(*TARGET_ECAL)\n",
    "bg_seeds_ss.downsample_spectra(target_bins=TARGET_BINS)\n",
    "bg_seeds_ss.normalize()\n",
    "\n",
    "static_syn = StaticSynthesizer(\n",
    "    samples_per_seed=STATIC_SYNTH_SPS,\n",
    "    bg_cps=STATIC_SYNTH_BG_CPS,\n",
    "    live_time_function=STATIC_SYNTH_LIVE_TIME_SAMPLING,\n",
    "    live_time_function_args=STATIC_SYNTH_LIVE_TIME_RANGE,\n",
    "    snr_function=STATIC_SYNTH_SNR_SAMPLING,\n",
    "    snr_function_args=STATIC_SYNTH_SNR_RANGE,\n",
    "    long_bg_live_time=STATIC_SYNTH_LONG_BG_CPS,\n",
    "    rng=rng\n",
    ")\n",
    "\n",
    "# Background\n",
    "mixed_bg_seeds_ss = SeedMixer(\n",
    "    bg_seeds_ss,\n",
    "    mixture_size=MIX_TRAIN_BG_SIZE,\n",
    "    dirichlet_alpha=MIX_TRAIN_BG_ALPHA,\n",
    "    random_state=RANDOM_SEED\n",
    ").generate(MIX_TRAIN_BG_SAMPLES)\n",
    "mixed_bg_seeds_ss.to_hdf(BG_MIX_FILE)\n",
    "\n",
    "# Train\n",
    "train_mixed_fg_seeds_ss = SeedMixer(\n",
    "    fg_seeds_ss,\n",
    "    mixture_size=fg_seeds_ss.n_samples,\n",
    "    dirichlet_alpha=expected_props * MIX_TRAIN_FG_LAMBDA,\n",
    "    random_state=RANDOM_SEED\n",
    ").generate(MIX_TRAIN_FG_SAMPLES)\n",
    "train_mixed_fg_seeds_ss.to_hdf(TRAIN_FG_MIX_FILE)\n",
    "train_ss, _ = static_syn.generate(\n",
    "    fg_seeds_ss=train_mixed_fg_seeds_ss,\n",
    "    bg_seeds_ss=mixed_bg_seeds_ss\n",
    ")\n",
    "train_ss.drop_spectra_with_no_contributors()\n",
    "train_ss.clip_negatives()\n",
    "train_ss.to_hdf(TRAIN_FILE)\n",
    "\n",
    "# Test\n",
    "static_syn.snr_function_args = STATIC_SYNTH_TEST_SNR_RANGE\n",
    "test_mixed_fg_seeds_ss = SeedMixer(\n",
    "    fg_seeds_ss,\n",
    "    mixture_size=fg_seeds_ss.n_samples,\n",
    "    dirichlet_alpha=expected_props * MIX_TRAIN_FG_LAMBDA,\n",
    "    random_state=RANDOM_SEED\n",
    ").generate(MIX_TEST_FG_SAMPLES)\n",
    "test_mixed_fg_seeds_ss.to_hdf(TEST_FG_MIX_FILE)\n",
    "test_ss, _ = static_syn.generate(\n",
    "    fg_seeds_ss=test_mixed_fg_seeds_ss,\n",
    "    bg_seeds_ss=mixed_bg_seeds_ss\n",
    ")\n",
    "test_ss.drop_spectra_with_no_contributors()\n",
    "test_ss.clip_negatives()\n",
    "test_ss.to_hdf(TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train model on 8192 channel data.\"\"\"\n",
    "if MODEL_TRAIN_ON_GPU:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"  # optionally select valid gpus\n",
    "else:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "time_str = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_name = f\"lpe{file_identifier}_{MODEL_SUP_LOSS}_{MODEL_UNSUP_LOSS}_{MODEL_BETA}_{time_str}\"\n",
    "\n",
    "fg_seeds_ss = read_hdf(FG_SEED_FILE)\n",
    "fg_seeds_ss, _ = fg_seeds_ss.split_fg_and_bg()\n",
    "fg_seeds_ss.drop_sources_columns_with_all_zeros()\n",
    "ood_seeds_ss = read_hdf(OOD_SEED_FILE)\n",
    "ood_seeds_ss, _ = ood_seeds_ss.split_fg_and_bg()\n",
    "ood_seeds_ss.drop_sources_columns_with_all_zeros()\n",
    "\n",
    "fg_seeds_ss = fg_seeds_ss.as_ecal(*TARGET_ECAL)\n",
    "fg_seeds_ss.downsample_spectra(target_bins=TARGET_BINS)\n",
    "fg_seeds_ss.normalize()\n",
    "ood_seeds_ss = ood_seeds_ss.as_ecal(*TARGET_ECAL)\n",
    "ood_seeds_ss.downsample_spectra(target_bins=TARGET_BINS)\n",
    "ood_seeds_ss.normalize()\n",
    "\n",
    "run_dir = MODEL_DIR\n",
    "callback_dir = os.path.join(run_dir, \"callbacks\")\n",
    "\n",
    "if not os.path.exists(callback_dir):\n",
    "    os.makedirs(callback_dir)\n",
    "\n",
    "if MODEL_TRAIN_ON_STATIC_SYNTH_DATA:\n",
    "    train_ss = read_hdf(TRAIN_FILE)\n",
    "    test_ss = read_hdf(TEST_FILE)\n",
    "else:\n",
    "    train_ss = read_hdf(TRAIN_FG_MIX_FILE)\n",
    "    test_ss = read_hdf(TEST_FG_MIX_FILE)\n",
    "\n",
    "model = LabelProportionEstimator(\n",
    "    hidden_layers=MODEL_HIDDEN_LAYERS,\n",
    "    sup_loss=MODEL_SUP_LOSS,\n",
    "    unsup_loss=MODEL_UNSUP_LOSS,\n",
    "    beta=MODEL_BETA,\n",
    "    fg_dict=None,\n",
    "    optimizer=MODEL_OPTIMIZER,\n",
    "    optimizer_kwargs=MODEL_OPTIMIZER_KWARGS,\n",
    "    learning_rate=MODEL_INIT_LR,\n",
    "    metrics=[\"mae\"],\n",
    "    hidden_layer_activation=MODEL_HIDDEN_LAYER_ACTIVATION,\n",
    "    kernel_l1_regularization=MODEL_KERNEL_L1_REG,\n",
    "    kernel_l2_regularization=MODEL_KERNEL_L2_REG,\n",
    "    activity_l1_regularization=MODEL_ACTIVITY_L1_REG,\n",
    "    activity_l2_regularization=MODEL_ACTIVITY_L2_REG,\n",
    "    dropout=MODEL_DROPOUT,\n",
    "    target_level=MODEL_TARGET_LEVEL,\n",
    "    bg_cps=STATIC_SYNTH_BG_CPS,\n",
    "    fit_spline=MODEL_TRAIN_ON_STATIC_SYNTH_DATA,\n",
    "    ood_fp_rate=MODEL_OOD_FPR,\n",
    "    spline_bins=MODEL_SPLINE_BINS,\n",
    "    spline_k=MODEL_SPLINE_K,\n",
    "    spline_s=MODEL_SPLINE_S\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\",\n",
    "        factor=0.1,\n",
    "        patience=MODEL_LR_SCHED_PATIENCE,\n",
    "        min_delta=MODEL_LR_SCHED_MIN_DELTA\n",
    "    ),\n",
    "    SaveTruthsandPredictionsCallback(\n",
    "        test_ss.spectra,\n",
    "        test_ss.sources,\n",
    "        model_name,\n",
    "        model.activation,\n",
    "        callback_dir=callback_dir\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    seeds_ss=fg_seeds_ss,\n",
    "    ss=train_ss,\n",
    "    batch_size=MODEL_BATCH_SIZE,\n",
    "    epochs=MODEL_EPOCHS,\n",
    "    validation_split=MODEL_VAL_SPLIT,\n",
    "    callbacks=callbacks,\n",
    "    patience=MODEL_PATIENCE,\n",
    "    verbose=True,\n",
    "    normalize_scaler=MODEL_SUP_NORMALIZE_SCALER,\n",
    "    normalize_sup_loss=MODEL_NORMALIZE_SUP_LOSS,\n",
    "    bg_cps=STATIC_SYNTH_BG_CPS,\n",
    "    es_min_delta=MODEL_MIN_DELTA\n",
    ")\n",
    "\n",
    "model.save(os.path.join(run_dir, f\"{model_name}.onnx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run forward pass on test set.\"\"\"\n",
    "tmp_ss = test_ss[:]\n",
    "model.predict(tmp_ss, bg_cps=STATIC_SYNTH_BG_CPS)\n",
    "y_true = tmp_ss.sources.values\n",
    "y_pred = tmp_ss.prediction_probas.values\n",
    "maes = mae(y_true.T, y_pred.T, multioutput=\"raw_values\")\n",
    "snrs = tmp_ss.spectra.values.sum(axis=1) / \\\n",
    "    np.sqrt(STATIC_SYNTH_BG_CPS * tmp_ss.info.live_time.values)\n",
    "recon_errors = tmp_ss.info[model.unsup_loss_func_name]\n",
    "print(f\"Test MAE: {np.mean(maes)}\")\n",
    "print(f\"Test MAE (SNR > 100): {np.mean(maes[np.where(snrs > 100)[0]])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_baldr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
