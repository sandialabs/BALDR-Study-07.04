{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Copyright 2024 National Technology & Engineering Solutions of Sandia, LLC (NTESS). \n",
    "    Under the terms of Contract DE-NA0003525 with NTESS, the U.S. Government retains certain rights in this software.\n",
    "\n",
    "**Step 5 - find the best models from hyperparameter sweeps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Imports\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import wandb\n",
    "from config import IMAGE_DIR, MODEL_WANDB_HOST, MODEL_WANDB_PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Fill in the sweep IDS for the hyperparameter search associated with each unsupervised loss.\"\"\"\n",
    "\n",
    "sweep_ids = {\n",
    "    \"chi_squared\": \"nj3btgc4\",\n",
    "    \"jsd\": \"bhg2t26r\",\n",
    "    \"pnll\": \"a4ebetbl\",\n",
    "    \"sse\": \"23cf8ebd\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Login to W&B.\"\"\"\n",
    "\n",
    "wandb.login(host=MODEL_WANDB_HOST)\n",
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get summary results for each run.\"\"\"\n",
    "\n",
    "sweep_val_maes = {}\n",
    "sweep_val_recon_errors = {}\n",
    "sweep_ood_fnrs = {}\n",
    "sweep_betas = {}\n",
    "sweep_lrs = {}\n",
    "\n",
    "best_run_inds = {}\n",
    "best_run_maes = []\n",
    "best_run_configs = {}\n",
    "\n",
    "for unsup_loss in sweep_ids.keys():\n",
    "    sweep = api.sweep(f\"{MODEL_WANDB_PROJECT}/{sweep_ids[unsup_loss]}\")\n",
    "    runs = sweep.runs\n",
    "    sweep_val_maes[unsup_loss] = [each.summary.get(\"final_tuning_val_mae\") for each in runs]\n",
    "    sweep_val_recon_errors[unsup_loss] = [each.summary.get(\"final_tuning_val_recon_error\") for each in runs]\n",
    "    sweep_ood_fnrs[unsup_loss] = [each.summary.get(\"final_test_ood_fnr\") for each in runs]\n",
    "    sweep_betas[unsup_loss] = [each.config.get(\"model_beta\") for each in runs]\n",
    "    sweep_lrs[unsup_loss] = [each.config.get(\"model_init_lr\") for each in runs]\n",
    "\n",
    "    best_run_inds[unsup_loss] = np.argmin(sweep_val_maes[unsup_loss])\n",
    "    best_run_maes.append(sweep_val_maes[unsup_loss][best_run_inds[unsup_loss]])\n",
    "    best_run_configs[unsup_loss] = runs[best_run_inds[unsup_loss]].config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plot results from sweeps.\"\"\"\n",
    "\n",
    "plt_names = [\"$\\chi^2$\",  \"JSD\", \"PNLL\", \"SSE\"]\n",
    "best_marker_size = 100\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10,6), sharey=True, sharex=True)\n",
    "for idx, ax in enumerate(axes.reshape(-1)):\n",
    "    unsup_loss = list(sweep_ids.keys())[idx]\n",
    "    ax.scatter(sweep_betas[unsup_loss], sweep_val_maes[unsup_loss], alpha=0.5, label=\"individual run\")\n",
    "\n",
    "    best_run = np.argmin(sweep_val_maes[unsup_loss])\n",
    "    ax.scatter(\n",
    "        sweep_betas[unsup_loss][best_run],\n",
    "        sweep_val_maes[unsup_loss][best_run],\n",
    "        color=\"red\",\n",
    "        alpha=1.0,\n",
    "        label=\"best run\",\n",
    "        marker=\"x\",\n",
    "        s=best_marker_size\n",
    "    )\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_title(plt_names[idx])\n",
    "\n",
    "axes[1,1].legend()\n",
    "fig.supylabel(\"Tuning Validation MAE\")\n",
    "fig.supxlabel(\"Beta\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(\n",
    "    IMAGE_DIR,\n",
    "    \"hp_sweep_mae_vs_beta.jpg\"\n",
    "), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10,6), sharey=True, sharex=True)\n",
    "for idx, ax in enumerate(axes.reshape(-1)):\n",
    "    unsup_loss = list(sweep_ids.keys())[idx]\n",
    "    ax.scatter(sweep_lrs[unsup_loss], sweep_val_maes[unsup_loss], alpha=0.5, label=\"individual run\")\n",
    "\n",
    "    best_run = np.argmin(sweep_val_maes[unsup_loss])\n",
    "    ax.scatter(\n",
    "        sweep_lrs[unsup_loss][best_run],\n",
    "        sweep_val_maes[unsup_loss][best_run],\n",
    "        color=\"red\",\n",
    "        alpha=1.0,\n",
    "        label=\"best run\",\n",
    "        marker=\"x\",\n",
    "        s=best_marker_size\n",
    "    )\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_title(plt_names[idx])\n",
    "\n",
    "axes[1,1].legend()\n",
    "fig.supylabel(\"Tuning Validation MAE\")\n",
    "fig.supxlabel(\"Initial Learning Rate\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(\n",
    "    IMAGE_DIR,\n",
    "    \"hp_sweep_lr_vs_beta.jpg\"\n",
    "), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10,6), sharey=True, sharex=True)\n",
    "for idx, ax in enumerate(axes.reshape(-1)):\n",
    "    unsup_loss = list(sweep_ids.keys())[idx]\n",
    "    ax.scatter(sweep_betas[unsup_loss], sweep_ood_fnrs[unsup_loss], alpha=0.5, label=\"model result\")\n",
    "\n",
    "    best_run = np.argmin(sweep_val_maes[unsup_loss])\n",
    "    ax.scatter(\n",
    "        sweep_betas[unsup_loss][best_run],\n",
    "        sweep_ood_fnrs[unsup_loss][best_run],\n",
    "        color=\"red\",\n",
    "        alpha=1.0,\n",
    "        label=\"best model\",\n",
    "        marker=\"x\",\n",
    "        s=best_marker_size\n",
    "    )\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_title(plt_names[idx])\n",
    "\n",
    "axes[1,1].legend()\n",
    "fig.supylabel(\"OOD FNR\")\n",
    "fig.supxlabel(\"Beta\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(\n",
    "    IMAGE_DIR,\n",
    "    \"hp_sweep_ood_fnr_vs_beta.jpg\"\n",
    "), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10,6), sharex=True)\n",
    "for idx, ax in enumerate(axes.reshape(-1)):\n",
    "    unsup_loss = list(sweep_ids.keys())[idx]\n",
    "    ax.scatter(sweep_betas[unsup_loss], sweep_val_recon_errors[unsup_loss], alpha=0.5, label=\"model result\")\n",
    "\n",
    "    best_run = np.argmin(sweep_val_maes[unsup_loss])\n",
    "    ax.scatter(\n",
    "        sweep_betas[unsup_loss][best_run],\n",
    "        sweep_val_recon_errors[unsup_loss][best_run],\n",
    "        color=\"red\",\n",
    "        alpha=1.0,\n",
    "        label=\"best model\",\n",
    "        marker=\"x\",\n",
    "        s=best_marker_size\n",
    "    )\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_title(plt_names[idx])\n",
    "\n",
    "axes[1,1].legend()\n",
    "fig.supylabel(\"Tuning Validation Reconstruction Error\")\n",
    "fig.supxlabel(\"Beta\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(\n",
    "    IMAGE_DIR,\n",
    "    \"hp_sweep_recon_error_vs_beta.jpg\"\n",
    "), dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
